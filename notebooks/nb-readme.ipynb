{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e1ceb3",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/codesport/monte-carlo/HEAD?urlpath=%2Fdoc%2Ftree%2F%2Fnotebooks%2Fnb-readme.ipynb)\n",
    " [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/codesport/monte-carlo/blob/master/notebooks/nb-readme.ipynb)\n",
    "\n",
    "# Author Credits\n",
    "\n",
    "This writeup was researched, tested, and compiled by **[Marcos](https://github.com/codesport)**. \n",
    "\n",
    "Marcos was a former **AVP in HY Risk Management** at Credit Suisse (now UBS) and former **International Risk Manager at Genworth Financial**.\n",
    "\n",
    "He may be reached through [Code Sport's contact us page](https://codesport.io/contact-us)\n",
    "\n",
    "# Table of Contents<!-- omit from toc -->\n",
    "- [Author Credits](#author-credits)\n",
    "- [Monte Carlo Simulations in Financial Risk Management](#monte-carlo-simulations-in-financial-risk-management)\n",
    "  - [1. What is a Monte Carlo Simulation?](#1-what-is-a-monte-carlo-simulation)\n",
    "    - [1.2.0 Definition and Geometric Brownian Motion (GBM)](#120-definition-and-geometric-brownian-motion-gbm)\n",
    "      - [1.2.1 üíª Python Setup](#121--python-setup)\n",
    "  - [2. Number of Simulations: 500 vs 5000](#2-number-of-simulations-500-vs-5000)\n",
    "    - [Visualization Example](#visualization-example)\n",
    "  - [3. Probability of Touching a Price](#3-probability-of-touching-a-price)\n",
    "    - [Mathematical Formulation](#mathematical-formulation)\n",
    "    - [Python Implementation](#python-implementation)\n",
    "      - [Intuition](#intuition)\n",
    "  - [4. Liquidation Risk Model](#4-liquidation-risk-model)\n",
    "    - [Python Implementation](#python-implementation-1)\n",
    "    - [Intuition](#intuition-1)\n",
    "  - [5. Value-at-Risk (VaR)](#5-value-at-risk-var)\n",
    "    - [Formula](#formula)\n",
    "    - [Python Implementation](#python-implementation-2)\n",
    "    - [Why the 5th Percentile?](#why-the-5th-percentile)\n",
    "  - [6. Drift (Œº) and Volatility (œÉ)](#6-drift-Œº-and-volatility-œÉ)\n",
    "    - [6a. Interpretation](#6a-interpretation)\n",
    "    - [6b. Volatility Estimation](#6b-volatility-estimation)\n",
    "    - [Which Historical Window Should You Use?](#which-historical-window-should-you-use)\n",
    "  - [7. Confidence Intervals and Percentiles](#7-confidence-intervals-and-percentiles)\n",
    "    - [Key Percentiles](#key-percentiles)\n",
    "    - [Visualization Example](#visualization-example-1)\n",
    "    - [Interpretation in DeFi Context](#interpretation-in-defi-context)\n",
    "  - [8. Business Requirement: Ensuring \\<5% Chance of Undercollateralization](#8-business-requirement-ensuring-5-chance-of-undercollateralization)\n",
    "    - [Mathematical Formulation](#mathematical-formulation-1)\n",
    "    - [8b: Python Implementation Set 1](#8b-python-implementation-set-1)\n",
    "    - [Explanation](#explanation)\n",
    "    - [Practical Implication](#practical-implication)\n",
    "  - [8c. Python Implementation Set 2](#8c-python-implementation-set-2)\n",
    "    - [Step 1: Define Liquidation Condition](#step-1-define-liquidation-condition)\n",
    "    - [Step 2: Iterate Over Thresholds](#step-2-iterate-over-thresholds)\n",
    "    - [Step 3: Interpret Results](#step-3-interpret-results)\n",
    "    - [üìä Interpretation](#-interpretation)\n",
    "  - [‚úÖ Conclusion](#-conclusion)\n",
    "- [Appendix I: GitHub Actions and Workflows](#appendix-i-github-actions-and-workflows)\n",
    "- [Appendix II: Scikit-learn](#appendix-ii-scikit-learn)\n",
    "  - [Python library for machine learning and statistical modeling.](#python-library-for-machine-learning-and-statistical-modeling)\n",
    "  - [Application to DeFi \\& Risk Modeling](#application-to-defi--risk-modeling)\n",
    "- [Appendix III: When Principal Component Analysis (PCA) is Used in Finance \\& Risk Modeling](#appendix-iii-when-principal-component-analysis-pca-is-used-in-finance--risk-modeling)\n",
    "  - [Multi-Asset Portfolio Risk](#multi-asset-portfolio-risk)\n",
    "  - [Yield Curve Modeling (Fixed Income)](#yield-curve-modeling-fixed-income)\n",
    "\n",
    "\n",
    "# Monte Carlo Simulations in Financial Risk Management\n",
    "\n",
    "\n",
    " **Monte Carlo simulations** allow us to model uncertainty, stress‚Äëtest financial portfolios, and make informed risk decisions.  \n",
    "\n",
    "This tutorial explains Monte Carlo methods through the lens of **DeFi liquidation risk** and **equity option pricing**, with equations, Python code, and **charts** for intuition.  \n",
    "\n",
    "We‚Äôll use **Ethereum (ETH)** as the consistent underlying asset\n",
    "\n",
    "---\n",
    "\n",
    "## 1. What is a Monte Carlo Simulation?\n",
    "\n",
    "A **Monte Carlo simulation** is a method for estimating the probability distribution of outcomes by generating a large number of random trials. A repeated random sampling technique used to estimate the probability distribution of uncertain outcomes.  \n",
    "\n",
    "### 1.2.0 Definition and Geometric Brownian Motion (GBM)\n",
    "\n",
    "\n",
    "In finance, asset prices are often modeled using **Geometric Brownian Motion (GBM)**:\n",
    "\n",
    "$$\n",
    "S_{t+\\Delta t} = S_t \\cdot \\exp\\Big( (\\mu - \\tfrac{1}{2}\\sigma^2)\\Delta t + \\sigma \\sqrt{\\Delta t}\\cdot Z \\Big)\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- $S_t$: Asset price at time t  \n",
    "- $\\mu$: Drift (expected return per step) = mean of returns \n",
    "- $\\sigma$: Volatility (standard deviation of returns)  \n",
    "- $\\Delta t$: Time increment  \n",
    "- $Z \\sim \\mathcal{N}(0,1)$: Standard normal random variable  \n",
    "\n",
    "#### 1.2.1 üíª Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99eb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# === STEP 1: Fetch historical price data (CoinGecko API for ETH) ===\n",
    "def fetch_crypto_data(coin_id=\"ethereum\", vs_currency=\"usd\", days=365):\n",
    "    url = f\"https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart\"\n",
    "    params = {\"vs_currency\": vs_currency, \"days\": days}\n",
    "    data = requests.get(url, params=params).json()\n",
    "    prices = [p[1] for p in data['prices']]\n",
    "    return pd.Series(prices)\n",
    "\n",
    "eth_prices = fetch_crypto_data()\n",
    "log_returns = np.log(eth_prices / eth_prices.shift(1)).dropna()\n",
    "\n",
    "# === STEP 2: Compute log returns to estimate drift (mu) and vol (sigma) ===\n",
    "mu = log_returns.mean()\n",
    "sigma = log_returns.std()\n",
    "S0 = eth_prices.iloc[-1] # last known ETH price. Latest ETH price (at t=0)\n",
    "\n",
    "print(f\"Estimated Daily Drift (mu): {mu:.6f}\")\n",
    "print(f\"Estimated Daily Volatility (sigma): {sigma:.6f}\")\n",
    "print(f\"Latest ETH Price): {S0:.2f}\")\n",
    "\n",
    "# === STEP 3: Monte Carlo Simulation ===\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c67e7c",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Full code us availble at: [notebooks/nb-base-mcs-stocks.ipynb](https://github.com/codesport/monte-carlo/tree/master/notebooks/nb-base-mcs-stocks.ipynb) \n",
    "\n",
    "> [!TIP]\n",
    "> Run simulation on Google Colab [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/codesport/monte-carlo/blob/master/notebooks/nb-base-mcs-stocks.ipynb)\n",
    "\n",
    "\n",
    "<!-->\n",
    "### 1.3.0 Monte Carlo for Option Pricing\n",
    "\n",
    "Monte Carlo methods are often used to price options. American options can be exercised at any time before expiration. European options cannot.\n",
    "\n",
    "\n",
    "Monte Carlo methods are widely used to price complex derivatives like American or path‚Äëdependent options (e.g., Asian options, barrier options).\n",
    "\n",
    "The key idea:\n",
    "\n",
    "* Simulate many possible stock paths under GBM.\n",
    "\n",
    "* Compute the payoff of the option along each path.\n",
    "\n",
    "* Discount the average payoff back to today.\n",
    "\n",
    "\n",
    "#### 1.4.0 European Call Option\n",
    "\n",
    "The Black‚ÄìScholes formula for a **European call option** is:\n",
    "\n",
    "$$\n",
    "C = S_0 N(d_1) - K e^{-rT} N(d_2)\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- $C$: Call price  \n",
    "- $S_0$: Current asset price  \n",
    "- $K$: Strike price  \n",
    "- $T$: Time to maturity (in years)  \n",
    "- $r$: Risk-free interest rate  \n",
    "- $N(\\cdot)$: Cumulative distribution function of the standard normal  \n",
    "- $d_1 = \\frac{\\ln(S_0/K) + (r + 0.5\\sigma^2)T}{\\sigma \\sqrt{T}}$  \n",
    "- $d_2 = d_1 - \\sigma\\sqrt{T}$\n",
    "\n",
    "##### 1.4.1 üíª Python Implementation for European Call Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae952e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def european_call_price(S0, K, T, r, sigma):\n",
    "    d1 = (np.log(S0 / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    return S0 * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "\n",
    "# Example: Pricing ETH European Call Option\n",
    "S0 = 2000   # Current ETH price\n",
    "K = 2100    # Strike price\n",
    "T = 0.5     # Time to maturity (0.5 years)\n",
    "r = 0.03    # Risk-free rate\n",
    "sigma = 0.5 # Volatility (50%)\n",
    "\n",
    "price = european_call_price(S0, K, T, r, sigma)\n",
    "print(f\"European Call Option Price: {price:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82039cdf",
   "metadata": {},
   "source": [
    "#### 1.5.0 American Call Options\n",
    "\n",
    "American options allow early exercise, making closed-form solutions more complex.\n",
    "One numerical method is the Longstaff‚ÄìSchwartz Monte Carlo algorithm, which uses regression to estimate the continuation value.\n",
    "\n",
    "\n",
    "The valuation relies on the Longstaff‚ÄìSchwartz least squares method, which estimates the continuation value via regression. The value of an American call option can be expressed as:\n",
    "\n",
    "$$\n",
    "C_0 = \\max_{t \\leq T} \\; \\mathbb{E}\\Big[ e^{-r t} \\cdot \\max(S_t - K, 0) \\,\\Big|\\, \text{optimal exercise policy} \\Big]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $C_0$ = value of the American call  \n",
    "- $S_t$ = simulated stock price at time $t$  \n",
    "- $K$ = strike price  \n",
    "- $r$ = risk free interest rate  \n",
    "- $T$ = expiration time  \n",
    "- ‚Äúoptimal exercise policy‚Äù = decision rule from regression continuation value  \n",
    "\n",
    "##### 1.5.1 üíª American Call Option Pricing via Least Squares Monte Carlo (LSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Simulate Geometric Brownian Motion paths ---\n",
    "def simulate_gbm(S0, r, sigma, T, steps, sims):\n",
    "    dt = T / steps\n",
    "    paths = np.zeros((steps+1, sims))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, steps+1):\n",
    "        Z = np.random.standard_normal(sims)\n",
    "        paths[t] = paths[t-1] * np.exp((r - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z)\n",
    "    return paths\n",
    "\n",
    "# --- Step 2: Price American Call using LSM ---\n",
    "def price_american_call(S0, K, r, sigma, T, steps=50, sims=5000):\n",
    "    dt = T / steps\n",
    "    paths = simulate_gbm(S0, r, sigma, T, steps, sims)\n",
    "    payoffs = np.maximum(paths - K, 0)\n",
    "\n",
    "    V = payoffs[-1]  # option values at maturity\n",
    "\n",
    "    for t in reversed(range(1, steps)):\n",
    "        itm = payoffs[t] > 0  # in-the-money paths\n",
    "        if np.any(itm):\n",
    "            X = paths[t, itm]\n",
    "            Y = V[itm] * np.exp(-r * dt)  # discounted continuation values\n",
    "\n",
    "            # Regression to estimate continuation value\n",
    "            coeffs = np.polyfit(X, Y, 2)\n",
    "            continuation = np.polyval(coeffs, X)\n",
    "\n",
    "            # Exercise if immediate payoff better than continuation\n",
    "            exercise = payoffs[t, itm]\n",
    "            V[itm] = np.where(exercise > continuation, exercise, V[itm] * np.exp(-r * dt))\n",
    "        V[~itm] = V[~itm] * np.exp(-r * dt)\n",
    "\n",
    "    return np.mean(V) * np.exp(-r * dt)\n",
    "\n",
    "S0 = 3700    # ETH starting price\n",
    "K = 3800     # Strike price\n",
    "r = 0.02     # 2% risk-free rate\n",
    "sigma = 0.5  # 50% annual volatility\n",
    "T = 0.25     # 3 months to maturity\n",
    "\n",
    "price = price_american_call(S0, K, r, sigma, T)\n",
    "print(f\"American Call Option Price: ${price:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8379b7",
   "metadata": {},
   "source": [
    "-->\n",
    "---\n",
    "## 2. Number of Simulations: 500 vs 5000\n",
    "\n",
    "Monte Carlo simulations generate random paths for the underlying asset's price.  The number of simulations chosen directly affects both the **accuracy** and the **computational cost**.\n",
    "\n",
    "For example, this line: `paths = np.zeros((rows, columns))` generates a 2D matrix of size row x column and fills it with zeros\n",
    "\n",
    "We then initialize position 0x0 of our matrix with the current asset price of S0: `paths[0] = S0`\n",
    "\n",
    "\n",
    "- **500 simulations**\n",
    "  - Faster to run, less accurate. Higher variance in estimates\n",
    "  - Less accurate results due to higher sampling error\n",
    "  - Useful for quick estimates or testing\n",
    "\n",
    "- **5000 simulations**\n",
    "  - Slower, but results converge toward true distribution (Law of Large Numbers).\n",
    "  - Smoother distributions of outcomes\n",
    "  - More accurate estimates of tail risks (e.g., Value-at-Risk)\n",
    "  - Higher computational cost but often necessary for risk-sensitive decisions\n",
    "\n",
    " **Pro Tip:** Use more paths until results stabilize, balancing speed vs accuracy.\n",
    "\n",
    "### Visualization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4dc090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sim_counts = [500, 5000]\n",
    "colors = [\"red\", \"blue\"]\n",
    "\n",
    "for sims, color in zip(sim_counts, colors):\n",
    "    paths = np.zeros((30, sims))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, 30):\n",
    "        Z = np.random.standard_normal(sims)\n",
    "        paths[t] = paths[t-1] * np.exp((mu - 0.5*sigma**2) + sigma*Z)\n",
    "    plt.plot(paths[:, :10], color=color, alpha=0.4, label=f\"{sims} sims\" if sims==500 else \"\")\n",
    "\n",
    "plt.title(\"ETH Monte Carlo Simulation: 500 vs 5000 Simulations\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"ETH Price (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6e95d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Probability of Touching a Price\n",
    "\n",
    "In finance, we often need to estimate the probability that an asset‚Äôs price touches (falls below or rises above) a critical level within a given time horizon.\n",
    "\n",
    "For example, in lending protocols, liquidation may occur if the asset price drops below a certain threshold.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "The probability that ETH touches a barrier $B$ at least once within horizon $T$ is:\n",
    "\n",
    "$$\n",
    "P(\\text{touch}) = \\frac{\\left| \\{ \\text{simulated paths where } \\min_{t \\leq T} S_t \\leq B \\} \\right|}{\\text{Total Paths}}\n",
    "$$\n",
    "\n",
    "> [!TIP]\n",
    "> In probability/statistics, instead of `#` for ‚Äúnumber of,‚Äù use cardinality notation with absolute values: \n",
    "> `#{sumlatioins}` becomes `|simulations|`\n",
    "\n",
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def probability_of_touch(S0, mu, sigma, T, barrier, simulations=5000):\n",
    "    paths = np.zeros((T, simulations))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, T):\n",
    "        Z = np.random.standard_normal(simulations)\n",
    "        paths[t] = paths[t-1] * np.exp((mu - 0.5*sigma**2) + sigma*Z)\n",
    "    \n",
    "    # Check if barrier touched in each simulation\n",
    "    touched = np.any(paths <= barrier, axis=0)\n",
    "    return touched.mean()\n",
    "\n",
    "# Example: Probability ETH touches $1800 in 30 days\n",
    "barrier = 1800\n",
    "T = 30\n",
    "prob_touch = probability_of_touch(S0, mu, sigma, T, barrier)\n",
    "print(f\"Probability ETH touches ${barrier} in {T} days: {prob_touch:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40093f",
   "metadata": {},
   "source": [
    "#### Intuition\n",
    "If the barrier is far below the current price or LTV, the probability of touch will be low.\n",
    "\n",
    "If the barrier is close to or above the current price or LTV, the probability increases sharply.\n",
    "\n",
    "This technique is widely used in barrier option pricing and in estimating probabilty of liquidation (risk assessment) in DeFi lending protocols.\n",
    "\n",
    "---\n",
    "## 4. Liquidation Risk Model\n",
    "\n",
    "In DeFi lending, borrowers provide collateral (e.g., ETH) to take a loan in stablecoins or another asset.  \n",
    "The **Loan-to-Value (LTV)** ratio measures the risk of liquidation:\n",
    "\n",
    "$$\n",
    "\\text{LTV}_t = \\frac{L}{C \\cdot S_t}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- $L$: Loan value (USD)  \n",
    "- $C$: Collateral amount (ETH)  \n",
    "- $S_t$: ETH price at time $t$  \n",
    "\n",
    "A liquidation occurs if:\n",
    "\n",
    "$$\n",
    "S_t \\leq \\frac{L}{\\text{LTV}_{crit} \\cdot C}\n",
    "$$\n",
    "\n",
    "\n",
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def probability_of_liquidation(S0, mu, sigma, T, loan_usd, collateral_eth, ltv_crit, simulations=5000):\n",
    "    paths = np.zeros((T, simulations))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, T):\n",
    "        Z = np.random.standard_normal(simulations)\n",
    "        paths[t] = paths[t-1] * np.exp((mu - 0.5*sigma**2) + sigma*Z)\n",
    "    \n",
    "    # Compute LTV paths\n",
    "    collateral_values = paths * collateral_eth\n",
    "    ltv_paths = loan_usd / collateral_values\n",
    "    \n",
    "    # Check if liquidation threshold breached\n",
    "    liquidations = np.any(ltv_paths >= ltv_crit, axis=0)\n",
    "    return liquidations.mean()\n",
    "\n",
    "# Example: Liquidation risk\n",
    "loan_usd = 25000\n",
    "collateral_eth = 10\n",
    "ltv_crit = 0.8\n",
    "T = 30\n",
    "\n",
    "prob_liq = probability_of_liquidation(S0, mu, sigma, T, loan_usd, collateral_eth, ltv_crit)\n",
    "print(f\"Probability of liquidation in {T} days: {prob_liq:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488690c",
   "metadata": {},
   "source": [
    "### Intuition\n",
    "\n",
    "- **Higher collateral** or **lower loan amount** reduces liquidation risk.  \n",
    "- **Lower ETH price** or **higher volatility** increases risk.  \n",
    "- DeFi Protocols set liquidation thresholds ($\\text{LTV}_{crit}$) to protect lenders\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Value-at-Risk (VaR)\n",
    "\n",
    "VaR answers: ‚ÄúWhat‚Äôs the worst I can lose with 95% confidence in T days?‚Äù\n",
    "\n",
    "**Value-at-Risk (VaR)** is a widely used risk measure that estimates the maximum potential loss of a portfolio within a given time horizon at a specified confidence level.\n",
    "\n",
    "For example, a **95% VaR** represents the maximum loss you would expect **95% of the time** over the period considered.\n",
    "\n",
    "### Formula\n",
    "\n",
    "For a Monte Carlo simulation:\n",
    "\n",
    "$$\n",
    "VaR_{95} = \\text{Percentile}_{5\\%}(\\text{Portfolio Returns})\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- $VaR_{95}$: Value-at-Risk at 95% confidence  \n",
    "- $\\text{Percentile}_{5\\%}$: 5th percentile of simulated returns or portfolio values  \n",
    "\n",
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d54ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def value_at_risk(S0, mu, sigma, T, loan_usd, collateral_eth, simulations=5000, percentile=5):\n",
    "    paths = np.zeros((T, simulations))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, T):\n",
    "        Z = np.random.standard_normal(simulations)\n",
    "        paths[t] = paths[t-1] * np.exp((mu - 0.5*sigma**2) + sigma*Z)\n",
    "\n",
    "    final_prices = paths[-1]\n",
    "    portfolio_values = final_prices * collateral_eth - loan_usd\n",
    "    var_value = np.percentile(portfolio_values, percentile)\n",
    "    return var_value\n",
    "\n",
    "loan_usd = 25000\n",
    "collateral_eth = 10\n",
    "T = 30\n",
    "\n",
    "var_95 = value_at_risk(S0, mu, sigma, T, loan_usd, collateral_eth)\n",
    "print(f\"95% Value-at-Risk over {T} days: ${var_95:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1562cd",
   "metadata": {},
   "source": [
    "### Why the 5th Percentile?\n",
    "\n",
    "We examine the **5th percentile** of outcomes because:\n",
    "\n",
    "- It represents a **worst-case scenario** within the 95% confidence band.  \n",
    "- It helps quantify **tail risk** (rare but severe losses).  \n",
    "- It provides a benchmark for determining **capital requirements** and **collateral safety margins** in DeFi lending.  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Drift (Œº) and Volatility (œÉ)\n",
    "\n",
    "Monte Carlo simulations of asset prices using **Geometric Brownian Motion (GBM)** require two critical parameters: **drift (Œº)** and **volatility (œÉ)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_returns = np.log(prices / prices.shift(1)).dropna()\n",
    "mu = log_returns.mean()\n",
    "sigma = log_returns.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1daf1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6a. Interpretation\n",
    "\n",
    "If you want to model n-day drift and vol, you scale depending on how many periods your horizon spans:\n",
    "\n",
    "- **Drift (Œº)**:  \n",
    "  **average expected log return per time step** (e.g., per day if you data feed is daily closing prices).  \n",
    "  Over $n$ days:\n",
    "\n",
    "  $$\n",
    "  \\mu_n = \\mu_{daily} \\cdot n\n",
    "  $$\n",
    "\n",
    "- **Volatility (œÉ)**:  \n",
    "  Measures the **uncertainty or dispersion** of returns (per day).  \n",
    "  Over $n$ days:\n",
    "\n",
    "  $$\n",
    "  \\sigma_n = \\sigma_{daily} \\cdot \\sqrt{n}\n",
    "  $$\n",
    "\n",
    "**Where:**\n",
    "- $\\mu_{daily}$: mean daily log return  \n",
    "- $\\sigma_{daily}$: standard deviation of daily log returns  \n",
    "- $n$: number of days in the forecast horizon  \n",
    "\n",
    "In other words:  \n",
    "- Drift gives the **directional tendency** of price.  \n",
    "- Volatility gives the **scale of randomness** (how wide the distribution of possible outcomes is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e9f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days = 252\n",
    "mu_annual = mu_daily * trading_days\n",
    "sigma_annual = sigma_daily * np.sqrt(trading_days)\n",
    "# TODO: Add print f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412dc8e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6b. Volatility Estimation\n",
    "\n",
    "Volatility is typically estimated from **historical log returns**:\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N \\big(r_i - \\bar{r}\\big)^2}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- $r_i$: log return on day $i$  \n",
    "- $\\bar{r}$: mean of the log returns  \n",
    "- $N$: number of historical observations  \n",
    "\n",
    "**Python Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dummy data set\n",
    "eth_prices = pd.Series([3000, 3020, 3050, 3010, 3100])\n",
    "# Compute drift (mu) and volatility (sigma) from ETH daily log returns\n",
    "log_returns = np.log(eth_prices / eth_prices.shift(1)).dropna()\n",
    "mu = log_returns.mean()\n",
    "sigma = log_returns.std()\n",
    "\n",
    "print(f\"Estimated daily drift (Œº): {mu:.6f}\")\n",
    "print(f\"Estimated daily volatility (œÉ): {sigma:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea01bb9",
   "metadata": {},
   "source": [
    "### Which Historical Window Should You Use?\n",
    "\n",
    "- **Short windows (e.g., last 30 days):**  \n",
    "  Capture **recent market volatilty behavior**.  Useful for near‚Äëterm predictions.\n",
    "\n",
    "- **Longer windows (e.g., 365 days):**  \n",
    "  Provide **stability** in estimates but may lag in capturing regime changes.  \n",
    "\n",
    "**Guideline 1:**  Use shorter lookback for predictions, longer lookback for risk limits.\n",
    "* Use shorter windows for trading models.\n",
    "\n",
    "* Use longer windows for risk management models.\n",
    "\n",
    "**Guideline 2:**  \n",
    "For modeling ETH liquidation risk over 30 days, using **365 days of volatility data** is common, as it balances accuracy and stability.  \n",
    "However, during highly volatile periods, **shorter windows** may better reflect the current environment.\n",
    "\n",
    "> [!NOTE]\n",
    "> For our risk modeling we calculate volatilty using n-days of volatilty.\n",
    "> **Where:**\n",
    "> n  =  intended holding period of the asset\n",
    ">\n",
    "> Additionally, to account for seasonality we may also use pricing data over the same period but 1 year prior. \n",
    "> For example, for n = 7-day holding period:\n",
    ">\n",
    ">If we intend to hold asset from August 7, 2025 to August 14, 2025,  we'll compute œÉ using both August 7, 2024 to August 14, 2024 and July 31, 2025 to August 7, 2025.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Confidence Intervals and Percentiles\n",
    "\n",
    "Monte Carlo simulations produce a distribution of possible asset prices.  \n",
    "To interpret this distribution, we often use **confidence intervals** (percentiles).\n",
    "\n",
    "---\n",
    "\n",
    "### Key Percentiles\n",
    "\n",
    "- **5th Percentile (P5):**  \n",
    "  Represents a **bearish / worst-case scenario**.  \n",
    "  In liquidation modeling, it helps quantify severe downside risk.  \n",
    "\n",
    "- **50th Percentile (P50 / Median):**  \n",
    "  Represents the **most likely outcome** in the middle of the distribution.  \n",
    "  This is often plotted as the central ‚Äúexpected path.‚Äù  \n",
    "\n",
    "- **95th Percentile (P95):**  \n",
    "  Represents a **bullish / best-case scenario**, showing optimistic outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "### Visualization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebdf68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate percentiles\n",
    "p5 = np.percentile(paths, 5, axis=1)\n",
    "p50 = np.percentile(paths, 50, axis=1)\n",
    "p95 = np.percentile(paths, 95, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(p50, label=\"Median (50th Percentile)\", color=\"blue\")\n",
    "plt.fill_between(range(T), p5, p95, color=\"lightblue\", alpha=0.4, \n",
    "                 label=\"5th‚Äì95th Percentile Range\")\n",
    "plt.title(f\"ETH Monte Carlo Simulation ({T} days)\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"ETH Price (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e710ffb4",
   "metadata": {},
   "source": [
    "### Interpretation in DeFi Context\n",
    "\n",
    "- **Liquidation Risk:**  \n",
    "  If the **5th percentile path** crosses your liquidation threshold,  there‚Äôs at least a **5% chance** you‚Äôll be liquidated in the given time horizon.  \n",
    "\n",
    "- **Protocol Risk Management:**  \n",
    "  DeFi lending protocols may use **95% confidence bands** to set **safe collateral ratios**.  \n",
    "\n",
    "- **Investor View:**  \n",
    "  Traders can evaluate the **upside vs downside balance** by comparing the **95th and 5th percentile paths**.  \n",
    "\n",
    "---\n",
    "\n",
    "## 8. Business Requirement: Ensuring <5% Chance of Undercollateralization\n",
    "\n",
    "A common business requirement in DeFi lending is to ensure that  \n",
    "there is less than a **5% probability of undercollateralization** across all loans. \n",
    "(i.e., loan value exceeding collateral value) within a specified horizon.\n",
    "\n",
    "\n",
    "For example, you run a DeFi protocol that wants to manage the risk of bad debt:\n",
    "\n",
    "> ‚ÄúWe want the probability of undercollateralization (liquidation) to stay below 5% in the next 30 days.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "Undercollateralization occurs when:\n",
    "\n",
    "$$\n",
    "\\text{LTV}_t \\geq 1\n",
    "$$\n",
    "\n",
    "To maintain safety, protocols set a critical liquidation threshold ($\\text{LTV}_{crit}$) such that:\n",
    "\n",
    "$$\n",
    "P(\\text{LTV}_t \\geq \\text{LTV}_{crit} \\text{ for some } t \\leq T) < 5\\%\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 8b: Python Implementation Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70043b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def probability_of_liquidation(S0, mu, sigma, T, loan_usd, collateral_eth, ltv_crit, simulations=5000):\n",
    "    paths = np.zeros((T, simulations))\n",
    "    paths[0] = S0\n",
    "    for t in range(1, T):\n",
    "        Z = np.random.standard_normal(simulations)\n",
    "        paths[t] = paths[t-1] * np.exp((mu - 0.5*sigma**2) + sigma*Z)\n",
    "    \n",
    "    # Compute LTV paths\n",
    "    collateral_values = paths * collateral_eth\n",
    "    ltv_paths = loan_usd / collateral_values\n",
    "    \n",
    "    # Check if liquidation threshold breached\n",
    "    liquidations = np.any(ltv_paths >= ltv_crit, axis=0)\n",
    "    return liquidations.mean()\n",
    "\n",
    "def safe_liquidation_threshold(S0, mu, sigma, T, loan_usd, collateral_eth, simulations=5000, target_prob=0.05):\n",
    "    thresholds = np.linspace(0.5, 0.95, 20)\n",
    "    for ltv_crit in thresholds:\n",
    "        prob = probability_of_liquidation(S0, mu, sigma, T, loan_usd, collateral_eth, ltv_crit, simulations)\n",
    "        if prob < target_prob:\n",
    "            return ltv_crit, prob\n",
    "    return None, None\n",
    "\n",
    "loan_usd = 25000\n",
    "collateral_eth = 10\n",
    "T = 30\n",
    "\n",
    "ltv_safe, prob_safe = safe_liquidation_threshold(S0, mu, sigma, T, loan_usd, collateral_eth)\n",
    "if ltv_safe:\n",
    "    print(f\"Set LTV threshold at {ltv_safe:.0%} ‚Üí Probability of liquidation: {prob_safe:.2%}\")\n",
    "else:\n",
    "    print(\"No safe threshold found within tested range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33a751",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- This function **iterates over candidate LTV thresholds**  \n",
    "  to find the highest LTV level that keeps liquidation risk below 5%.  \n",
    "\n",
    "- If no threshold is found, the protocol must require  \n",
    "  **more collateral** or **smaller loans**.  \n",
    "\n",
    "### Practical Implication\n",
    "\n",
    "- **Borrowers:** Can assess how close they are to unsafe territory.  \n",
    "- **Lenders/Protocols:** Can set thresholds to minimize systemic risk.  \n",
    "- **Risk Managers:** Can justify risk frameworks with quantitative evidence.  \n",
    "\n",
    "\n",
    "\n",
    "## 8c. Python Implementation Set 2\n",
    "\n",
    "### Step 1: Define Liquidation Condition\n",
    "\n",
    "$$\n",
    "\text{Liquidation if } S_t \\leq frac{L}{\text{LTV}_{crit} \\cdot C}\n",
    "$$\n",
    "\n",
    "### Step 2: Iterate Over Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2459bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ltv in np.linspace(0.6, 0.9, 7):\n",
    "    liq_price = loan_usd / (ltv * collateral_eth)\n",
    "    liqs = np.sum(np.any(paths <= liq_price, axis=0))\n",
    "    prob_liq = liqs / sims\n",
    "    print(f\"LTV {ltv:.0%}: Liquidation Probability = {prob_liq:.2%}\")\n",
    "    if prob_liq < 0.05:\n",
    "        print(f\"‚úÖ Safe threshold: {ltv:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e673f39",
   "metadata": {},
   "source": [
    "### Step 3: Interpret Results\n",
    "\n",
    "- At LTV = 80%, probability of liquidation = 12% ‚Üí too risky.  \n",
    "- At LTV = 65%, probability of liquidation = 3% ‚Üí acceptable.\n",
    "\n",
    "üìà Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c970cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltvs = np.linspace(0.6, 0.9, 7)\n",
    "probs = []\n",
    "for ltv in ltvs:\n",
    "    liq_price = loan_usd / (ltv * collateral_eth)\n",
    "    liqs = np.sum(np.any(paths <= liq_price, axis=0))\n",
    "    probs.append(liqs / sims)\n",
    "\n",
    "plt.plot(ltvs, probs, marker=\"o\")\n",
    "plt.axhline(0.05, color=\"red\", linestyle=\"--\", label=\"5% Risk Target\")\n",
    "plt.title(\"Probability of Liquidation vs. LTV Threshold\")\n",
    "plt.xlabel(\"LTV Threshold\")\n",
    "plt.ylabel(\"Probability of Liquidation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d4f4af",
   "metadata": {},
   "source": [
    "### üìä Interpretation\n",
    "\n",
    "- The curve shows how risk increases with higher LTV thresholds.  \n",
    "- The red dashed line = 5% risk policy.  \n",
    "- The intersection = maximum safe LTV.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclusion\n",
    "\n",
    "By combining math, Monte Carlo simulations, and visuals, we can:\n",
    "\n",
    "- Understand ETH price uncertainty via GBM  \n",
    "- Quantify liquidation risk under different thresholds  \n",
    "- Set safe LTV levels that align with business risk appetite  \n",
    "\n",
    "This approach works in DeFi, US equities, or derivatives pricing. It turns abstract math into actionable risk management.\n",
    "\n",
    "\n",
    "# Appendix I: GitHub Actions and Workflows\n",
    "\n",
    "I created a Python script and a .yml file that does the following:\n",
    "\n",
    "1. Whenever I push a new version of the README.md GitHub actions bot runs my \"Markdown to Jupyter\" notebook conversion script\n",
    "\n",
    "2. Then commit and push the newly generated Jupyter notebook to a folder called mynotebooks this my repo.\n",
    "\n",
    "3. `GITHUB_TOKEN` is automatically created by GitHub Actions for each workflow run, but it must be given write permissions via the repos setting:\n",
    "   - Settings ‚Üí Actions ‚Üí General -> Scroll to Workflow permissions -> \"Read and write permissions\" \n",
    "\n",
    "\n",
    "# Appendix II: Scikit-learn\n",
    "\n",
    "## Python library for machine learning and statistical modeling.\n",
    "\n",
    "* Tools for model selection, validation, and preprocessing\n",
    "\n",
    "* Suited for medium-sized datasets (unlike TensorFlow/PyTorch, which are better for very large-scale deep learning)\n",
    "\n",
    "* Ideal for prototyping, teaching, and applied machine learning projects\n",
    "\n",
    "## Application to DeFi & Risk Modeling \n",
    "\n",
    "* Volatility forecasting (via regression models)\n",
    "\n",
    "* Classification (predicting likelihood of liquidation events)\n",
    "\n",
    "* Dimensionality reduction (e.g., analyzing factors affecting ETH prices)\n",
    "\n",
    "# Appendix III: When Principal Component Analysis (PCA) is Used in Finance & Risk Modeling\n",
    "\n",
    "## Multi-Asset Portfolio Risk\n",
    "\n",
    "PCA is most valuable when you‚Äôre modeling many correlated risk factors or assets. For example, a Monte Carlo simulation for a portfolio of 50 stocks (or multiple DeFi assets)\n",
    "\n",
    "## Yield Curve Modeling (Fixed Income)\n",
    "\n",
    "Common in bond pricing and risk models.\n",
    "\n",
    "PCA often finds:\n",
    "\n",
    "- PC1: Level of the yield curve\n",
    "\n",
    "- PC2: Slope of the curve\n",
    "\n",
    "- PC3: Curvature of the curve\n",
    "\n",
    "These three factors explain ~95% of yield curve movements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
